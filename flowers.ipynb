{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-08-30 12:54:20 +03:00)\n"
     ]
    }
   ],
   "source": [
    "# !pip install -q ipython-autotime\n",
    "%load_ext autoreload\n",
    "%load_ext autotime\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already extracted\n",
      "time: 109 ms (started: 2023-08-30 12:54:20 +03:00)\n"
     ]
    }
   ],
   "source": [
    "import requests, os, tarfile\n",
    "from tqdm import tqdm\n",
    "from data_download import download, extract_tgz\n",
    "\n",
    "dataset_url = r'https://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz'\n",
    "segmentations = r'https://www.robots.ox.ac.uk/~vgg/data/flowers/102/102segmentations.tgz'\n",
    "chi_distance = r'https://www.robots.ox.ac.uk/~vgg/data/flowers/102/distancematrices102.mat'\n",
    "labels = r'https://www.robots.ox.ac.uk/~vgg/data/flowers/102/imagelabels.mat'\n",
    "splits = r'https://www.robots.ox.ac.uk/~vgg/data/flowers/102/setid.mat'\n",
    "\n",
    "OVERWRITE = False\n",
    "\n",
    "download(dataset_url, dataset_url.split('/')[-1], force_redownload=OVERWRITE)\n",
    "# download(segmentations, segmentations.split('/')[-1], force_redownload=OVERWRITE)\n",
    "# download(chi_distance, chi_distance.split('/')[-1], force_redownload=OVERWRITE)\n",
    "download(labels, labels.split('/')[-1], force_redownload=OVERWRITE)\n",
    "download(splits, splits.split('/')[-1], force_redownload=OVERWRITE)\n",
    "extract_tgz(r'102flowers.tgz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.3 s (started: 2023-08-30 12:54:20 +03:00)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data_processing import prepare_df, FlowerDataset\n",
    "\n",
    "\n",
    "split_path = r\"data/setid.mat\"\n",
    "labels_Path = r\"data/imagelabels.mat\"\n",
    "data_root = r\"data/102flowers/jpg\"\n",
    "train_split, test_split, val_split = prepare_df(split_path, labels_Path, data_root)\n",
    "\n",
    "transformsations = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# train_dataset = FlowerDataset(train_split, transform=transformsations)\n",
    "# test_dataset = FlowerDataset(test_split, transform=transformsations)\n",
    "# val_dataset = FlowerDataset(val_split, transform=transformsations)\n",
    "\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "# train_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.08 s (started: 2023-08-30 12:54:21 +03:00)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchsummary\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-08-30 12:54:23 +03:00)\n"
     ]
    }
   ],
   "source": [
    "def accuray_fn(ypred, y_true):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of the prediction\n",
    "    \"\"\"\n",
    "    return (ypred.argmax(dim=1) == y_true).sum() / len(ypred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-08-30 12:54:23 +03:00)\n"
     ]
    }
   ],
   "source": [
    "class Resnet50Flower102(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = torchvision.models.resnet50(pretrained=pretrained)\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 102),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 562 ms (started: 2023-08-30 12:54:23 +03:00)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# from models  import Resnet50Flower102\n",
    "from tqdm import tqdm\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = 'cpu'\n",
    "model = Resnet50Flower102(pretrained=True).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# optimizer = torch.optim.Adam(model.model.fc.parameters(), lr=3e-4)\n",
    "train_dataset = FlowerDataset(train_split, transform=transformsations)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1538 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=False)\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    for x, y in tqdm(train_loader, total=len(train_loader), desc=\"Training\", leave=False):\n",
    "        x, y = next(iter(train_loader))\n",
    "        optimizer.zero_grad()\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_hat = model(x)\n",
    "        # y_hat, y\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        total_acc += accuray_fn(y_hat, y)\n",
    "\n",
    "    print(f\"Epoch {epoch} Loss : {total_loss / len(train_loader)}\")\n",
    "    print(f\"Epoch {epoch} Accuracy: {total_loss/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2023-08-30 12:47:35 +03:00)\n"
     ]
    }
   ],
   "source": [
    "# for Epoch in range(20):\n",
    "#     total_loss = 0\n",
    "#     accuracy = 0\n",
    "#     for x, y in tqdm(train_loader, total=len(train_loader), desc=\"Training\", leave=False):\n",
    "#         x, y = next(iter(train_loader))\n",
    "#         x = x.to(device)\n",
    "#         y = y.to(device).type(torch.FloatTensor).requires_grad_(True)\n",
    "#         optimizer.zero_grad()\n",
    "#         y_hat = model(x).argmax(dim=1).type(torch.FloatTensor).requires_grad_(True)\n",
    "#         loss = loss_fn( y_hat, y)\n",
    "#         accuray = (y_hat == y).sum()/len(y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         total_loss += loss.item()\n",
    "#     print(y, y_hat)\n",
    "#     print(total_loss/len(train_loader))\n",
    "#     print(accuray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
