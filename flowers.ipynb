{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q ipython-autotime\n",
    "# %load_ext autoreload\n",
    "# %load_ext autotime\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n",
      "File already exists\n",
      "File already exists\n",
      "File already extracted\n"
     ]
    }
   ],
   "source": [
    "import requests, os, tarfile\n",
    "from tqdm import tqdm\n",
    "from data_download import download, extract_tgz\n",
    "\n",
    "dataset_url = r'https://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz'\n",
    "segmentations = r'https://www.robots.ox.ac.uk/~vgg/data/flowers/102/102segmentations.tgz'\n",
    "chi_distance = r'https://www.robots.ox.ac.uk/~vgg/data/flowers/102/distancematrices102.mat'\n",
    "labels = r'https://www.robots.ox.ac.uk/~vgg/data/flowers/102/imagelabels.mat'\n",
    "splits = r'https://www.robots.ox.ac.uk/~vgg/data/flowers/102/setid.mat'\n",
    "\n",
    "OVERWRITE = False\n",
    "\n",
    "download(dataset_url, dataset_url.split('/')[-1], force_redownload=OVERWRITE)\n",
    "# download(segmentations, segmentations.split('/')[-1], force_redownload=OVERWRITE)\n",
    "# download(chi_distance, chi_distance.split('/')[-1], force_redownload=OVERWRITE)\n",
    "download(labels, labels.split('/')[-1], force_redownload=OVERWRITE)\n",
    "download(splits, splits.split('/')[-1], force_redownload=OVERWRITE)\n",
    "extract_tgz(r'102flowers.tgz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data_processing import prepare_df, FlowerDataset\n",
    "\n",
    "\n",
    "split_path = r\"data/setid.mat\"\n",
    "labels_Path = r\"data/imagelabels.mat\"\n",
    "data_root = r\"data/102flowers/jpg\"\n",
    "train_split, test_split, val_split = prepare_df(split_path, labels_Path, data_root)\n",
    "\n",
    "transformsations = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# train_dataset = FlowerDataset(train_split, transform=transformsations)\n",
    "# test_dataset = FlowerDataset(test_split, transform=transformsations)\n",
    "# val_dataset = FlowerDataset(val_split, transform=transformsations)\n",
    "\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "# train_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchsummary\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuray_fn(ypred, y_true):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of the prediction\n",
    "    \"\"\"\n",
    "    return (ypred.argmax(dim=1) == y_true).sum() / len(ypred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\envs\\torch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models  import Resnet50Flower102\n",
    "from tqdm import tqdm\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = 'cpu'\n",
    "model = Resnet50Flower102(pretrained=True).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# optimizer = torch.optim.Adam(model.model.fc.parameters(), lr=3e-4)\n",
    "train_dataset = FlowerDataset(train_split, transform=transformsations)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# writer = SummaryWriter()\n",
    "\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=4, shuffle=False)\n",
    "# EPOCHS = 10\n",
    "\n",
    "# for epoch in range(EPOCHS):\n",
    "#     total_loss = 0\n",
    "#     total_acc = 0\n",
    "#     for x, y in tqdm(\n",
    "#         train_loader, total=len(train_loader), desc=\"Training\", leave=False\n",
    "#     ):\n",
    "#         x, y = x.to(device), y.to(device)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         y_hat = model(x)\n",
    "#         loss = loss_fn(y_hat, y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         total_loss += loss.item()\n",
    "#         total_acc += accuray_fn(y_hat, y)\n",
    "\n",
    "#     # writer.add_scalar(\"Loss/train\", total_loss / len(train_loader), epoch)\n",
    "#     # writer.add_scalar(\"Accuracy/train\", total_acc / len(train_loader), epoch)\n",
    "\n",
    "#     print(f\"Epoch {epoch} Loss : {total_loss / len(train_loader)}\")\n",
    "#     print(f\"Epoch {epoch} Accuracy: {total_acc/len(train_loader)}\")\n",
    "\n",
    "# writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss : 0.003039207818139204\n",
      "Epoch 0 Accuracy: 0.0058517553843557835\n",
      "Epoch 1 Loss : 0.0\n",
      "Epoch 1 Accuracy: 0.0065019503235816956\n",
      "Epoch 2 Loss : 0.0\n",
      "Epoch 2 Accuracy: 0.0065019503235816956\n",
      "Epoch 3 Loss : 0.0\n",
      "Epoch 3 Accuracy: 0.0065019503235816956\n",
      "Epoch 4 Loss : 0.0\n",
      "Epoch 4 Accuracy: 0.0065019503235816956\n",
      "Epoch 5 Loss : 0.0\n",
      "Epoch 5 Accuracy: 0.0065019503235816956\n",
      "Epoch 6 Loss : 0.0\n",
      "Epoch 6 Accuracy: 0.0065019503235816956\n",
      "Epoch 7 Loss : 0.0\n",
      "Epoch 7 Accuracy: 0.0065019503235816956\n",
      "Epoch 8 Loss : 0.0\n",
      "Epoch 8 Accuracy: 0.0065019503235816956\n",
      "Epoch 9 Loss : 0.0\n",
      "Epoch 9 Accuracy: 0.0065019503235816956\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=False)\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    for i in range(10):\n",
    "        x, y = next(iter(train_loader))\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(x)\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        total_acc += accuray_fn(y_hat, y)\n",
    "\n",
    "    # writer.add_scalar(\"Loss/train\", total_loss / len(train_loader), epoch)\n",
    "    # writer.add_scalar(\"Accuracy/train\", total_acc / len(train_loader), epoch)\n",
    "\n",
    "    print(f\"Epoch {epoch} Loss : {total_loss / len(train_loader)}\")\n",
    "    print(f\"Epoch {epoch} Accuracy: {total_acc/len(train_loader)}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
